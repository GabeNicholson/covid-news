{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0edde1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from tqdm import tqdm\n",
    "# import seaborn as sns\n",
    "# tqdm.pandas()\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ac3d2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_name = 'us_covid_april_2021-april_2022_(2022-09-26).parquet'\n",
    "# df_name = 'eur_covid_april_2021-april_2022_(2022-10-06).parquet'\n",
    "\n",
    "df_name_1 = \"eur_covid_april_2021-april_2022_(2022-10-06).parquet\"\n",
    "df_name_2 = \"eur_covid_mar_2020-april_2021_(2022-10-04).parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f893b138",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'comp_files/analysis_us_covid_april_2021-april_2022_(2022-09-26).parquet'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_parquet(\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mcomp_files/analysis_\u001b[39;49m\u001b[39m{\u001b[39;49;00mdf_name\u001b[39m}\u001b[39;49;00m\u001b[39m'\u001b[39;49m, \n\u001b[1;32m      2\u001b[0m                              columns\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39marticle_id\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mdate\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mpublisher\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mtitle\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mpage_num\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39msource_type\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m      3\u001b[0m                                \u001b[39m'\u001b[39;49m\u001b[39mcity\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mauthor\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mLexileScore\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mprediction\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m      4\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mNumber of unique articles being analyzed: \u001b[39m\u001b[39m{\u001b[39;00mdf\u001b[39m.\u001b[39marticle_id\u001b[39m.\u001b[39mnunique()\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/covid-news/lib/python3.10/site-packages/pandas/io/parquet.py:493\u001b[0m, in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, storage_options, use_nullable_dtypes, **kwargs)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    447\u001b[0m \u001b[39mLoad a parquet object from the file path, returning a DataFrame.\u001b[39;00m\n\u001b[1;32m    448\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[39mDataFrame\u001b[39;00m\n\u001b[1;32m    490\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    491\u001b[0m impl \u001b[39m=\u001b[39m get_engine(engine)\n\u001b[0;32m--> 493\u001b[0m \u001b[39mreturn\u001b[39;00m impl\u001b[39m.\u001b[39;49mread(\n\u001b[1;32m    494\u001b[0m     path,\n\u001b[1;32m    495\u001b[0m     columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[1;32m    496\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[1;32m    497\u001b[0m     use_nullable_dtypes\u001b[39m=\u001b[39;49muse_nullable_dtypes,\n\u001b[1;32m    498\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    499\u001b[0m )\n",
      "File \u001b[0;32m~/miniforge3/envs/covid-news/lib/python3.10/site-packages/pandas/io/parquet.py:233\u001b[0m, in \u001b[0;36mPyArrowImpl.read\u001b[0;34m(self, path, columns, use_nullable_dtypes, storage_options, **kwargs)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[39mif\u001b[39;00m manager \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39marray\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    231\u001b[0m     to_pandas_kwargs[\u001b[39m\"\u001b[39m\u001b[39msplit_blocks\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m  \u001b[39m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m--> 233\u001b[0m path_or_handle, handles, kwargs[\u001b[39m\"\u001b[39m\u001b[39mfilesystem\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m _get_path_or_handle(\n\u001b[1;32m    234\u001b[0m     path,\n\u001b[1;32m    235\u001b[0m     kwargs\u001b[39m.\u001b[39;49mpop(\u001b[39m\"\u001b[39;49m\u001b[39mfilesystem\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    236\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[1;32m    237\u001b[0m     mode\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    238\u001b[0m )\n\u001b[1;32m    239\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    240\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi\u001b[39m.\u001b[39mparquet\u001b[39m.\u001b[39mread_table(\n\u001b[1;32m    241\u001b[0m         path_or_handle, columns\u001b[39m=\u001b[39mcolumns, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m    242\u001b[0m     )\u001b[39m.\u001b[39mto_pandas(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mto_pandas_kwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/covid-news/lib/python3.10/site-packages/pandas/io/parquet.py:102\u001b[0m, in \u001b[0;36m_get_path_or_handle\u001b[0;34m(path, fs, storage_options, mode, is_dir)\u001b[0m\n\u001b[1;32m     92\u001b[0m handles \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m     94\u001b[0m     \u001b[39mnot\u001b[39;00m fs\n\u001b[1;32m     95\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_dir\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[39m# fsspec resources can also point to directories\u001b[39;00m\n\u001b[1;32m    101\u001b[0m     \u001b[39m# this branch is used for example when reading from non-fsspec URLs\u001b[39;00m\n\u001b[0;32m--> 102\u001b[0m     handles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m    103\u001b[0m         path_or_handle, mode, is_text\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, storage_options\u001b[39m=\u001b[39;49mstorage_options\n\u001b[1;32m    104\u001b[0m     )\n\u001b[1;32m    105\u001b[0m     fs \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    106\u001b[0m     path_or_handle \u001b[39m=\u001b[39m handles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/miniforge3/envs/covid-news/lib/python3.10/site-packages/pandas/io/common.py:795\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    786\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(\n\u001b[1;32m    787\u001b[0m             handle,\n\u001b[1;32m    788\u001b[0m             ioargs\u001b[39m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    791\u001b[0m             newline\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    792\u001b[0m         )\n\u001b[1;32m    793\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    794\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 795\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(handle, ioargs\u001b[39m.\u001b[39;49mmode)\n\u001b[1;32m    796\u001b[0m     handles\u001b[39m.\u001b[39mappend(handle)\n\u001b[1;32m    798\u001b[0m \u001b[39m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'comp_files/analysis_us_covid_april_2021-april_2022_(2022-09-26).parquet'"
     ]
    }
   ],
   "source": [
    "df = pd.read_parquet(f'comp_files/analysis_{df_name}', \n",
    "                             columns=['article_id', 'date', 'publisher', 'title', 'page_num', 'source_type',\n",
    "                               'city', 'author', 'LexileScore', 'prediction'])\n",
    "print(f'Number of unique articles being analyzed: {df.article_id.nunique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccbec954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique articles being analyzed: 185844\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_parquet(f'comp_files/analysis_{df_name_1}', \n",
    "                             columns=['article_id', 'date', 'publisher', 'title', 'page_num', 'source_type',\n",
    "                               'city', 'author', 'LexileScore', 'prediction'])\n",
    "print(f'Number of unique articles being analyzed: {df1.article_id.nunique()}')\n",
    "\n",
    "df2 = pd.read_parquet(f'comp_files/analysis_{df_name_2}', \n",
    "                             columns=['article_id', 'date', 'publisher', 'title', 'page_num', 'source_type',\n",
    "                               'city', 'author', 'LexileScore', 'prediction'])\n",
    "print(f'Number of unique articles being analyzed: {df2.article_id.nunique()}')\n",
    "\n",
    "full_df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "def shrink_df_size(dataframe):\n",
    "    dataframe['article_id'] = pd.factorize(dataframe['article_id'])[0]\n",
    "    dataframe['article_id'] = dataframe['article_id'].astype('int32')\n",
    "    dataframe['prediction'] = dataframe['prediction'].astype('int8')\n",
    "    dataframe['page_num'] = dataframe['page_num'].astype('category')\n",
    "    dataframe = dataframe.drop(columns=['title', 'city', 'source_type', 'author', 'LexileScore'])\n",
    "    return dataframe\n",
    "\n",
    "full_df = shrink_df_size(full_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c66337",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"us_full_covid.parquet\"\n",
    "\n",
    "full_df.to_parquet(f'email_analysis/{file_name}', index=False, compression='brotli')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29685775",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3e20e341",
   "metadata": {},
   "source": [
    "# Testing Section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8d9b21",
   "metadata": {},
   "source": [
    "We want to get the relative number of front page articles being published compared overtime since all publication numbers went down during the end of omicron wave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ead82e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# article_grouped_df['is_oped'] = np.where(article_grouped_df['article_id'].isin(editorial_df['article_id']), True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e061d999",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "covid-news",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "ba768a010b84f1c09a4bb22ce6535c84a2bcdedd527dc40cbd91b132a400313e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
