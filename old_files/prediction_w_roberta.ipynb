{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/.conda/envs/torch_rona/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "Device name: Tesla K80\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from covid import RobertaClassifier, SentimentData\n",
    "import pandas as pd\n",
    "from transformers import RobertaTokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import multiprocessing as mp\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique articles: 164481\n"
     ]
    }
   ],
   "source": [
    "df_name = 'can-apr2021-apr2022.csv'\n",
    "# df_name = 'us-mar-apr2022-headline.csv'\n",
    "# df_name = 'us_news_commentary.csv'\n",
    "\n",
    "df = pd.read_csv('csv/no_txt_' + df_name, parse_dates=['date'], index_col=[0]) \n",
    "print(f'Number of unique articles: {df.article_id.nunique()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reformatting and tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "article_id    0\n",
       "date          0\n",
       "publisher     0\n",
       "title         0\n",
       "page_num      0\n",
       "pairs         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.page_num.fillna('None', inplace=True)\n",
    "assert (df.isna().sum() == 0).all() == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "Device name: Tesla K80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/.conda/envs/torch_rona/lib/python3.8/site-packages/torch/serialization.py:593: SourceChangeWarning: source code of class 'torch.nn.modules.sparse.Embedding' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/ec2-user/SageMaker/.conda/envs/torch_rona/lib/python3.8/site-packages/torch/serialization.py:593: SourceChangeWarning: source code of class 'torch.nn.modules.normalization.LayerNorm' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/ec2-user/SageMaker/.conda/envs/torch_rona/lib/python3.8/site-packages/torch/serialization.py:593: SourceChangeWarning: source code of class 'torch.nn.modules.dropout.Dropout' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/ec2-user/SageMaker/.conda/envs/torch_rona/lib/python3.8/site-packages/torch/serialization.py:593: SourceChangeWarning: source code of class 'torch.nn.modules.container.ModuleList' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/ec2-user/SageMaker/.conda/envs/torch_rona/lib/python3.8/site-packages/torch/serialization.py:593: SourceChangeWarning: source code of class 'torch.nn.modules.linear.Linear' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/ec2-user/SageMaker/.conda/envs/torch_rona/lib/python3.8/site-packages/torch/serialization.py:593: SourceChangeWarning: source code of class 'torch.nn.modules.activation.Tanh' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():       \n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
    "    print('Device name:', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "# Instantiate Finetuned Classifier\n",
    "finetuned_rob = RobertaClassifier().to(device)\n",
    "finetuned_rob.load_state_dict(torch.load('/home/ec2-user/SageMaker/pre_trained_model/covid_checkpoint.pth', map_location=device));\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"/home/ec2-user/SageMaker/pre_trained_tokenizer\")\n",
    "\n",
    "\n",
    "def tokenizer_mp(sent):\n",
    "    return len(tokenizer.encode(sent, add_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (783 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (911 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (527 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (600 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "##------------------------------ USE THIS FOR Covid ------------------------------\n",
    "with mp.Pool(mp.cpu_count()) as pool:\n",
    "    df['len_tokenized'] = pool.map(tokenizer_mp, df['pairs'])    \n",
    "    \n",
    "df = df[(df['len_tokenized'] < 500) & (df['len_tokenized'] > 20)]\n",
    "df['sentences'] = df['pairs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##------------------------------ USE THIS FOR TITLES ------------------------------\n",
    "\n",
    "with mp.Pool(mp.cpu_count()) as pool:\n",
    "    df['len_tokenized'] = pool.map(tokenizer_mp, df['title'])    \n",
    "    \n",
    "# For TITLES:\n",
    "df = df[df['len_tokenized'] < 500]\n",
    "df['sentences'] = df['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = df.len_tokenized.max()\n",
    "print(f'Max length of tokenized pair sentences: {MAX_LEN}')\n",
    "print(f'Percentage of sentences with a tokenized length greater than 300 {len(df[df.len_tokenized > 300])/len(df)}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using a subset of the original dataframe to speed up model runtime**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164116\n",
      "164116\n"
     ]
    }
   ],
   "source": [
    "subset_df = df # Using entire timeline.\n",
    "print(subset_df.article_id.nunique())\n",
    "print(df.article_id.nunique())\n",
    "subset_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Predicting with Roberta**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rob_predict(model, testing_loader):\n",
    "    model.eval()\n",
    "    prediction_list = []\n",
    "    score_list = []\n",
    "    with torch.no_grad(): \n",
    "        for data in tqdm(testing_loader):\n",
    "            ids = data['ids'].to(device, dtype = torch.long)\n",
    "            mask = data['mask'].to(device, dtype = torch.long)\n",
    "            token_type_ids = data['token_type_ids'].to(device, dtype=torch.long)\n",
    "            outputs = F.softmax(model(ids, mask, token_type_ids), dim=-1)\n",
    "            score, prediction = torch.max(outputs.data, dim=1)\n",
    "            prediction_list.extend(prediction.cpu().numpy())\n",
    "            score_list.extend(score.cpu().numpy())\n",
    "        return prediction_list , score_list\n",
    "    \n",
    "def run_model(dataframe):\n",
    "    testing_set = SentimentData(dataframe, tokenizer , max_len = 500)\n",
    "    testing_loader = DataLoader(testing_set, batch_size=15, num_workers=0) \n",
    "    prediction_list, score_list = rob_predict(finetuned_rob, testing_loader)\n",
    "    interm = pd.DataFrame({'prediction': prediction_list,'score': score_list})\n",
    "    test_df = pd.concat((dataframe, interm),axis=1)\n",
    "    return test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 334/53967 [17:11<46:01:19,  3.09s/it]"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predicted_df = run_model(dataframe = subset_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_name = 'can-apr2020-mar2021.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    487933\n",
       "1    321568\n",
       "Name: prediction, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_df.to_csv('csv/analysis_' + df_name)\n",
    "predicted_df.prediction.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv/analysis_can-apr2020-mar2021.csv\n"
     ]
    }
   ],
   "source": [
    "print('csv/analysis_' + df_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "72a60da5162cf5d458cb2db71a4e7796a0c7fc52f842b27edfae3b82254df2c6"
  },
  "kernelspec": {
   "display_name": "torch_rona",
   "language": "python",
   "name": "torch_rona"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
